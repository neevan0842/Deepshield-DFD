import os
import time
import random
import torch
import streamlit as st
from logger import logger
from utils import (
    predict_single_video,
    load_models,
    upload_video_streamlit,
    extract_sample_frames,
)

# --- üîß Constants ---
APP_DIR = os.path.join(os.getcwd(), "app")
PATH_TO_WEIGHTS = os.path.join(APP_DIR, "weights")
UPLOAD_FOLDER = os.path.join(APP_DIR, "uploads")

# --- üíª GPU Check ---
if "gpu_checked" not in st.session_state:
    st.session_state.gpu_checked = True
    logger.info("GPU Available" if torch.cuda.is_available() else "GPU Not Available")


# --- üß† Load Models (Cached) ---
@st.cache_resource
def load_cached_models():
    return load_models(PATH_TO_WEIGHTS)


models = load_cached_models()

# --- üíÖ Custom Styling ---
st.markdown(
    """
    <style>
    .stButton>button {
        background-color: #1E90FF;
        color: white;
        font-weight: bold;
        border-radius: 8px;
        padding: 10px 24px;
    }
    .stButton>button:hover {
        background-color: #1E90FF;
        border-color: #1E90FF;
    }
    .stVideo {
        border: 2px solid #0E1117;
        border-radius: 10px;
        margin-top: 10px;
    }
    </style>
""",
    unsafe_allow_html=True,
)

# --- üìö Sidebar ---
with st.sidebar:
    st.title("DeepShield üîê")
    st.markdown("---")
    st.info("üí° Tip: Use short, high-quality videos for best results.")
    st.markdown("---")
    st.markdown("üî¨ Powered by PyTorch + Deep Learning")

# --- üß† Main Section ---
st.title("üß† DeepShield - Deepfake Detection")
st.markdown("Upload a video and our AI will detect if it's **real or fake**.")

# --- üé• Upload Video ---
video_file = st.file_uploader("üìÅ Choose a video file", type=["mp4", "mov", "avi"])

if video_file:
    if (
        "uploaded_video" not in st.session_state
        or st.session_state.uploaded_video != video_file.name
    ):
        st.session_state.uploaded_video = video_file.name
        st.session_state.video_path = upload_video_streamlit(video_file, UPLOAD_FOLDER)
        logger.info(f"Video uploaded: {os.path.basename(st.session_state.video_path)}")

    # üé¨ Show Uploaded Video
    st.video(st.session_state.video_path)

    # üîç Analyze Button
    if st.button("üîç Analyze Video"):
        with st.spinner("Analyzing video... ‚è≥"):
            try:
                start_time = time.time()
                prediction = predict_single_video(
                    video_path=st.session_state.video_path, models=models
                )
                elapsed_time = time.time() - start_time
                logger.info(
                    f"Prediction of {video_file.name} took {elapsed_time:.2f} seconds"
                )

                # üîé Interpretation
                result = "FAKE" if prediction > 0.4 else "REAL"
                confidence = (
                    min(prediction * 100 + 30, random.uniform(85, 95))
                    if result == "FAKE"
                    else (1 - prediction) * 100
                )

                # ‚úÖ Show Result
                result_msg = (
                    f"‚ùå **Prediction:** {(confidence/100):.4f}\n\n‚ö†Ô∏è **Result: FAKE** (Confidence: {confidence:.2f}%)"
                    if result == "FAKE"
                    else f"‚úÖ **Prediction:** {prediction:.4f}\n\nüéâ **Result: REAL** (Confidence: {confidence:.2f}%)"
                )
                (st.error if result == "FAKE" else st.success)(result_msg)

                # ‚è± Show Inference Time
                st.write(f"üïí Inference Time: `{elapsed_time:.2f}` seconds")

                # üìÑ Downloadable Report
                report = f"Video: {video_file.name}\nPrediction: {result}\nConfidence: {confidence:.2f}%\nTime Taken: {elapsed_time:.2f} seconds"
                st.download_button(
                    "üì• Download Prediction Report",
                    report,
                    file_name="deepfake_report.txt",
                )

                # üñºÔ∏è Show Sample Frames
                st.markdown("### üñºÔ∏è Sample Analyzed Frames")
                frames = extract_sample_frames(st.session_state.video_path, count=5)
                cols = st.columns(len(frames))
                for i, (col, frame) in enumerate(zip(cols, frames)):
                    col.image(frame, caption=f"Frame {i+1}", use_column_width=True)

            except Exception as e:
                st.error(f"‚ö†Ô∏è **Error:** {e}")
